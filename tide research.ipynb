{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9953b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger is initialized...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time \n",
    "import ccxt\n",
    "\n",
    "from config import TradingType\n",
    "from logger.logger_file import logger\n",
    "from data.data_management import Data_Manager\n",
    "from strategy.indicators_management import Indicators_Manager\n",
    "from strategy.strategy_management import Strategy_Manager\n",
    "from exchange.order_management import Order_Manager\n",
    "from performance.metrics import calc_position_metrics\n",
    "\n",
    "config = {'general': {'trading_type': 'BACKTEST',\n",
    "                      'klines_db_location': './database/binance_kline.db'},\n",
    "          'strategy': {'strategy': ['strategy.TF_tide_0:TF_tide_0'],\n",
    "                       'allocation_total_notional': 100_000,\n",
    "                       'allocation_per_pair_pct': 10,\n",
    "                       'timeframes': {\"15m\": \"15m\", \"1h\":\"1h\",\"4h\":\"4h\"},\n",
    "                       'indicators': {'atr': {'length': [14]},\n",
    "                                      'stdev': {'length':[14]},\n",
    "                                      'rsi': {'length': [14], 'close': ['close']},\n",
    "                                      'ema': {'length': [8, 13, 21, 34, 55, 89], 'close': ['close']}\n",
    "                                      },\n",
    "                       'initial_position_pct': 1,\n",
    "                       'trailing_engaged_upnl_pct': 6,  # not required- default will be 100 to prevent trigger\n",
    "                       'trailing_take_profit_upnl_pct': 4,\n",
    "                       'martingale_factor': 2,\n",
    "                       'stoploss': 10,\n",
    "                       'shorts_enabled': False},\n",
    "          'BACKTEST': {'comment': 'test',\n",
    "                       'pairs': ['BTCUSDT', 'ETHUSDT', 'XTZUSDT', 'XRPUSDT'],\n",
    "                       # , 'ATOMUSDT','ZECUSDT', 'ZILUSDT','ZRXUSDT', 'DOGEUSDT', 'XMRUSDT'],\n",
    "                       'workers': 4,\n",
    "                       'vectorised_indicators': True,\n",
    "                       'window': ['2019-01-01', '2022-06-15'],\n",
    "                       'klines_type': 'spot',\n",
    "                       'update_db': True,\n",
    "                       'slippage': 0.001,  # slippage.fixed(0.001) or slippage.dynamic() : SLIPPAGE\n",
    "                       'fee': 0.0004,\n",
    "                       'output_path': \"./backtests/\",\n",
    "                       'publish': True,\n",
    "                       'dash_port': 8000}\n",
    "          }\n",
    "\n",
    "pair = \"BTCUSDT\"\n",
    "strategy = config['strategy']['strategy'][0]\n",
    "strategy_instructions = [{'pair':pair,\n",
    "                          'strategy':strategy,\n",
    "                          'config':config} for pair in config[\"BACKTEST\"][\"pairs\"]]\n",
    "strategy_instruction = [i for i in strategy_instructions if i[\"pair\"]==pair][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "\"\"\"\n",
    "Pair wise backtest loop\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# strategy_instruction = strategy_instructions[-1]\n",
    "# UNPACK backtest instructions\n",
    "config = strategy_instruction[\"config\"]\n",
    "window = config['BACKTEST']['window']\n",
    "trading_type = TradingType(config[\"general\"][\"trading_type\"])\n",
    "# =============================================================================\n",
    "# Instantiate Trade Objects\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------\n",
    "# Order manager\n",
    "# -----------------------------------\n",
    "#TODO: for tradair implementation have to remove dependence on CCXT -> wire in callback from tradair client (fix engine)\n",
    "pair = strategy_instruction[\"pair\"]\n",
    "fee = config['BACKTEST'][\"fee\"]\n",
    "slippage = config['BACKTEST'][\"slippage\"]\n",
    "\n",
    "Order_manager = Order_Manager(trading_type=trading_type,\n",
    "                              slippage=slippage,\n",
    "                              fee=fee)\n",
    "\n",
    "# -----------------------------------\n",
    "# Strategy Manager\n",
    "# -----------------------------------\n",
    "#TODO: rename max_allocation to per_pair_allocation\n",
    "strategy = strategy_instruction['strategy']\n",
    "\n",
    "# Feed [strategy] section into strategy_manager\n",
    "config_strategy = {key:value for key,value in config[\"strategy\"].items() if key != \"strategy\"}\n",
    "config_strategy[\"strategy\"] = strategy\n",
    "\n",
    "Strategy_manager = Strategy_Manager(strategy=strategy,\n",
    "                                    config_strategy = config_strategy,\n",
    "                                    Order_manager = Order_manager,\n",
    "                                    verbose = False)\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Data and indicators manager\n",
    "# -----------------------------------\n",
    "try:\n",
    "    timeframes = config['strategy']['timeframes']\n",
    "except:\n",
    "    timeframes = None\n",
    "try:\n",
    "    indicators = config['strategy']['indicators']\n",
    "except:\n",
    "    indicators = None\n",
    "\n",
    "indicators_needed_by_datetime = datetime.strptime(window[0], \"%Y-%m-%d\") \n",
    "klines_db_location = config[\"general\"][\"klines_db_location\"]\n",
    "update_db = config[\"BACKTEST\"][\"update_db\"]\n",
    "klines_type = config[\"BACKTEST\"][\"klines_type\"]\n",
    "# Initialise indicators manager\n",
    "Indicators_manager = Indicators_Manager(indicators = indicators,\n",
    "                                        postprocess_klines=Strategy_manager.strategy.postprocess_klines,\n",
    "                                        preprocess_klines = Strategy_manager.strategy.preprocess_klines)\n",
    "Strategy_manager.strategy.Indicators_manager = Indicators_manager\n",
    "\n",
    "# Initialise data manager\n",
    "Data_manager = Data_Manager(timeframes=timeframes,\n",
    "                            indicators=indicators,\n",
    "                            indicators_needed_by_datetime=indicators_needed_by_datetime,\n",
    "                            klines_db_location=klines_db_location,\n",
    "                            update_db=False,\n",
    "                            klines_type=klines_type,\n",
    "                            Indicators_manager=Indicators_manager)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Load DATA beforehand\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------\n",
    "# load klines\n",
    "# -----------------------------------\n",
    "t0 = time.time()\n",
    "logger.info(\"Loading klines .... \")\n",
    "Data_manager.load_ohlcv(pair=pair)\n",
    "logger.info(f\"time taken to load klines {time.time() - t0}\")\n",
    "# klines_dict = Data_manager.klines_dict\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# calculate indicators \n",
    "# -----------------------------------\n",
    "if config[\"BACKTEST\"][\"vectorised_indicators\"]:\n",
    "    Data_manager.calc_all_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "klines_dict = Data_manager.klines_dict\n",
    "klines_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3a336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"BACKTEST\"][\"output_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "klines_dict[\"1m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54b4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b146028f",
   "metadata": {},
   "source": [
    "# CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888db9fd",
   "metadata": {},
   "source": [
    "## Catboost across multiple timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool,CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98734ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1m = klines_dict[\"1m\"].copy()\n",
    "df_15m = klines_dict[\"15m\"].copy()\n",
    "df_1h = klines_dict[\"1h\"].copy()\n",
    "df_4h = klines_dict[\"4h\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1m.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1045c",
   "metadata": {},
   "source": [
    "### a) concat all timeframe dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d2bd74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "temp=[]\n",
    "features = ['open', 'high', 'low', 'close', 'volume','quote_vol', 'nTrades','takerBuy_quoteAssetVol', 'takerBuy_baseAssetVol',\n",
    "            'ATRr_14', 'RSI_14', 'EMA_67',\n",
    "            'tide', 'ebb', 'flow']\n",
    "for timeframe,df in klines_dict.items():\n",
    "    temp_i = df[features].copy()\n",
    "    temp_i.dropna(inplace=True)\n",
    "    temp_i[\"tide\"] = temp_i[\"tide\"].astype(int)\n",
    "    temp_i = temp_i.add_suffix(f\"_{timeframe}\")\n",
    "    temp.append(temp_i)\n",
    "    \n",
    "df = reduce(lambda  left,right: pd.merge(left,right, left_index=True,right_index=True,how='outer'), temp)\n",
    "df.dropna(subset=[\"tide_1m\"],inplace=True)\n",
    "df.fillna(method=\"ffill\",inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://api.blockchain.info/charts/mempool-size?format=json&timespan=3year&sampled=false'\n",
    "data = json.loads(urlopen(url).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f964399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data[\"values\"])\n",
    "df1['x'] = pd.to_datetime(df1['x'], unit='s').round(\"1T\")\n",
    "df1.set_index(keys=['x'], inplace=True, drop=True)\n",
    "df1.rename(columns={\"y\":\"mempoolsize\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98002e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.merge(df,df1,right_index=True,left_index=True,how=\"left\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'./btcusdt_preprocessed.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd3af90",
   "metadata": {},
   "source": [
    "### b) Label generation using triple barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e203acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol(prices, span=100, delta=pd.Timedelta(hours=1)):\n",
    "    # 1. compute returns of the form p[t]/p[t-1] - 1\n",
    "    # 1.1 find the timestamps of p[t-1] values\n",
    "#     df0 = prices.index.searchsorted(prices.index - delta)\n",
    "#     df0 = df0[df0 > 0]\n",
    "#     # 1.2 align timestamps of p[t-1] to timestamps of p[t]\n",
    "#     df0 = pd.Series(prices.index[df0-1],index=prices.index[prices.shape[0]-df0.shape[0] : ])\n",
    "#     # 1.3 get values by timestamps, then compute returns\n",
    "#     df0 = prices.loc[df0.index] / prices.loc[df0.values].values - 1\n",
    "\n",
    "    df0 = prices.pct_change()\n",
    "    # 2. estimate rolling standard deviation\n",
    "    df0 = df0.ewm(span=span).std()\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a314e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizons(prices, delta=pd.Timedelta(minutes=15)):\n",
    "    t1 = prices.index.searchsorted(prices.index + delta)\n",
    "    t1 = t1[t1 < prices.shape[0]]\n",
    "    t1 = prices.index[t1]\n",
    "    t1 = pd.Series(t1, index=prices.index[:t1.shape[0]])\n",
    "    t1.name = \"t1\"\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_touches(prices, events, factors=[1, 1]):\n",
    "    '''\n",
    "    events: pd dataframe with columns\n",
    "    t1: timestamp of the next horizon\n",
    "    threshold: unit height of top and bottom barriers\n",
    "    side: the side of each bet\n",
    "    factors: multipliers of the threshold to set the height of \n",
    "           top/bottom barriers\n",
    "    '''\n",
    "    out = events[['t1']].copy(deep=True)\n",
    "    if factors[0] > 0: \n",
    "        thresh_uppr = factors[0] * events['threshold']\n",
    "    else:\n",
    "        thresh_uppr = pd.Series(index=events.index) # no uppr thresh\n",
    "    if factors[1] > 0:\n",
    "        thresh_lwr = -factors[1] * events['threshold']\n",
    "    else:\n",
    "        thresh_lwr = pd.Series(index=events.index)  # no lwr thresh\n",
    "    for loc, t1 in tqdm(events['t1'].iteritems()):\n",
    "        df0=prices[loc:t1]                              # path prices\n",
    "        df0=(df0 / prices[loc] - 1) * events.side[loc]  # path returns\n",
    "        out.loc[loc, 'stop_loss'] = df0[df0 < thresh_lwr[loc]].index.min()  # earliest stop loss\n",
    "        out.loc[loc, 'take_profit'] = \\\n",
    "        df0[df0 > thresh_uppr[loc]].index.min() # earliest take profit\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef405faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(touches):\n",
    "  out = touches.copy(deep=True)\n",
    "  # pandas df.min() ignores NaN values\n",
    "  first_touch = touches[['stop_loss', 'take_profit']].min(axis=1)\n",
    "  for loc, t in tqdm(first_touch.iteritems()):\n",
    "    if pd.isnull(t):\n",
    "      out.loc[loc, 'label'] = 0\n",
    "    elif t == touches.loc[loc, 'stop_loss']: \n",
    "      out.loc[loc, 'label'] = -1\n",
    "    else:\n",
    "      out.loc[loc, 'label'] = 1\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc49f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ohlc = df.copy()\n",
    "data_ohlc = data_ohlc.assign(threshold=get_vol(data_ohlc[\"close_1m\"])).dropna()\n",
    "t1=get_horizons(data_ohlc)\n",
    "data_ohlc = pd.merge(data_ohlc, t1, left_index=True, right_index=True, how=\"left\").dropna()\n",
    "# data_ohlc = data_ohlc.assign(t1=get_horizons(data_ohlc)).dropna()\n",
    "events = data_ohlc[['t1', 'threshold']] \n",
    "events = events.assign(side=pd.Series(1., events.index)) # long only\n",
    "touches = get_touches(data_ohlc[\"close_1m\"], events, [1,1])\n",
    "touches = get_labels(touches)\n",
    "data_ohlc = data_ohlc.assign(label=touches.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f291ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=467864-1\n",
    "prices= data_ohlc[\"close_1m\"].copy()\n",
    "factors = [1,1]\n",
    "out = events[['t1']].copy(deep=True)\n",
    "if factors[0] > 0: \n",
    "    thresh_uppr = factors[0] * events['threshold']\n",
    "else:\n",
    "    thresh_uppr = pd.Series(index=events.index) # no uppr thresh\n",
    "if factors[1] > 0:\n",
    "    thresh_lwr = -factors[1] * events['threshold']\n",
    "else:\n",
    "    thresh_lwr = pd.Series(index=events.index)  # no lwr thresh\n",
    "    \n",
    "loc = events.iloc[t,:].name\n",
    "t1=events[\"t1\"][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "        df0=prices[loc:t1]                              # path prices\n",
    "        df0=(df0 / prices[loc] - 1) * events.side[loc]  # path returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "        out.loc[loc, 'stop_loss'] = df0[df0 < thresh_lwr[loc]].index.min()  # earliest stop loss\n",
    "        out.loc[loc, 'take_profit'] = \\\n",
    "        df0[df0 > thresh_uppr[loc]].index.min() # earliest take profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0aff7",
   "metadata": {},
   "source": [
    "### c) train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df0.columns)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df0.copy()\n",
    "features = list(df.columns)\n",
    "#             ['tide_1m', 'ebb_1m', 'flow_1m', \n",
    "#             'tide_15m','ebb_15m', 'flow_15m', \n",
    "#             'tide_1h', 'ebb_1h', 'flow_1h',\n",
    "#             'tide_4h', 'ebb_4h', 'flow_4h']\n",
    "cat_features = ['tide_1m','tide_15m','tide_1h','tide_4h']\n",
    "# df[\"Y1\"] = df[\"close_1m\"].pct_change(periods=15).shift(-15).dropna()\n",
    "# df[\"Y\"]=np.where(df[\"Y1\"] > 0, 1, 0)\n",
    "df[\"Y1\"] = df[\"ATRr_14_1m\"].shift(-15).dropna()\n",
    "labels = [\"Y1\"]\n",
    "\n",
    "train_window = [\"2020-01-01\",\"2020-06-30\"]\n",
    "val_window = [\"2020-07-01\",\"2020-09-30\"]\n",
    "test_window = [\"2020-10-01\",\"2020-12-31\"]\n",
    "\n",
    "train_data = df.dropna()[train_window[0]:train_window[1]][features]\n",
    "train_labels = df.dropna()[train_window[0]:train_window[1]][labels]\n",
    "\n",
    "val_data = df.dropna()[val_window[0]:val_window[1]][features]\n",
    "val_labels = df.dropna()[val_window[0]:val_window[1]][labels]\n",
    "\n",
    "test_data = df.dropna()[test_window[0]:test_window[1]][features]\n",
    "test_labels = df.dropna()[test_window[0]:test_window[1]][labels]\n",
    "\n",
    "print(f\"train data window : {str(train_data.index[0])} - {str(train_data.index[-1])}\")\n",
    "print(f\"train label window: {str(train_labels.index[0])} - {str(train_labels.index[-1])}\")\n",
    "\n",
    "print(f\"val data window  : {str(val_data.index[0])} - {str(val_data.index[-1])}\")\n",
    "print(f\"val label window : {str(val_labels.index[0])} - {str(val_labels.index[-1])}\")\n",
    "\n",
    "print(f\"test data window  : {str(test_data.index[0])} - {str(test_data.index[-1])}\")\n",
    "print(f\"test label window : {str(test_labels.index[0])} - {str(test_labels.index[-1])}\")\n",
    "\n",
    "print(train_labels.hist())\n",
    "print(val_labels.hist())\n",
    "print(test_labels.hist())\n",
    "\n",
    "train_pool = Pool(data=train_data, label = train_labels)\n",
    "valid_pool = Pool(data=val_data, label = val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2946276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_T = CatBoostClassifier(task_type=\"GPU\",learning_rate=0.03, custom_loss = ['Accuracy'])\n",
    "model_T = CatBoostRegressor(task_type=\"GPU\",learning_rate=0.03)\n",
    "model_T.fit(train_pool, eval_set=valid_pool,\n",
    "       verbose=False,\n",
    "       plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e27d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_T.predict(test_data)\n",
    "plot_df=test_labels.copy()\n",
    "plot_df[\"pred_Y\"]= y_pred\n",
    "# plot_df.plot()\n",
    "df_fi = pd.DataFrame(model_T.feature_importances_, index=train_data.columns, ).sort_values(by=0,ascending=False)\n",
    "print(df_fi[df_fi>0.0].dropna())\n",
    "print(df_fi[df_fi==0.0].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d73f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "probs = model_T.predict_proba(test_data)\n",
    "plt.hist(probs,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy model: \", accuracy_score(test_labels, y_pred))\n",
    "print(\"Accuracy tide_1m : \", accuracy_score(test_labels, test_data[\"tide_1m\"]))\n",
    "print(\"Accuracy tide_15m : \", accuracy_score(test_labels, test_data[\"tide_15m\"]))\n",
    "print(\"Accuracy tide_1h : \", accuracy_score(test_labels, test_data[\"tide_1h\"]))\n",
    "print(\"Accuracy tide_4h : \", accuracy_score(test_labels, test_data[\"tide_4h\"]))\n",
    "# print(\"Accuracy tide vs pred : \", accuracy_score(y_pred, test_data[\"tide_1h\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test_labels.copy()\n",
    "test[\"y_pred\"] = y_pred\n",
    "test[\"prob\"] = df[\"close_1m\"][test_window[0]:test_window[1]] #probs[:,1]\n",
    "test[\"tide_1m\"]=test_data[\"tide_1m\"]\n",
    "test[\"tide_15m\"]=test_data[\"tide_15m\"]\n",
    "test[\"tide_1h\"]=test_data[\"tide_1h\"]\n",
    "test[\"tide_4h\"]=test_data[\"tide_4h\"]\n",
    "test[\"close_1m\"] = df[\"close_1m\"][test_window[0]:test_window[1]]\n",
    "test[\"ATRr_14_1m\"] = df[\"ATRr_14_1m\"][test_window[0]:test_window[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be27c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly_resampler import FigureWidgetResampler\n",
    "fig = FigureWidgetResampler(make_subplots(rows=8, cols=1,\n",
    "                    shared_xaxes=True,\n",
    "                    vertical_spacing = 0.055,\n",
    "                    row_heights=[1,1,1,1,1,1,1,3],\n",
    "                    specs=[[{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}],\n",
    "                           [{\"type\":\"scatter\"}]\n",
    "                           ],\n",
    "                    subplot_titles = (\"4h_tide\",\"1h_tide\",\"15m_tide\", \"1m_tide\",\"Y\",\"prob\", \"y_pred\", \"close\")\n",
    "                    ))\n",
    "row=1    \n",
    "for col in [\"tide_4h\",\"tide_1h\",\"tide_15m\",\"tide_1m\", \"Y1\", \"prob\", \"y_pred\", \"close_1m\"]:\n",
    "    print(col)\n",
    "    if col == \"close_1m\":\n",
    "        ax = go.Scattergl(x=test.index, y=test[\"close_1m\"],name=col)\n",
    "        fig.append_trace(ax,row=row,col=1)\n",
    "        row+=1\n",
    "    else:\n",
    "        ax = go.Scattergl(x=test.index, y=test[col],name=col)\n",
    "        fig.append_trace(ax,row=row,col=1)\n",
    "        row+=1\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    margin=dict(\n",
    "        l=50,\n",
    "        r=50,\n",
    "        b=100,\n",
    "        t=100,\n",
    "        pad=4\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904f867d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'type': 'scatter'}, {'type': 'scatter'}]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[{\"type\":\"scatter\"}]*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82a0ddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len_df = 86371\n",
    "test_size = 10\n",
    "min_train_size = 86351\n",
    "n_splits = 11\n",
    "np.floor((len_df - test_size - min_train_size) / (n_splits - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "833bb6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift = (len_df - test_size - min_train_size) / (n_splits - 1)\n",
    "shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c074f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
